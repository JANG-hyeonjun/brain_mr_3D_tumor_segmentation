{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2D_Segmentation_model_pytorch.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Akz1skBkuFHJ","executionInfo":{"status":"ok","timestamp":1638099203521,"user_tz":-540,"elapsed":8142,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"e3e3aa48-b703-4209-aea7-5bcf92cfcfd4"},"source":["pip install git+https://github.com/qubvel/segmentation_models.pytorch"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/qubvel/segmentation_models.pytorch\n","  Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-bpbjp8ng\n","  Running command git clone -q https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-bpbjp8ng\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch==0.2.1) (0.11.1+cu111)\n","Collecting pretrainedmodels==0.7.4\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 2.9 MB/s \n","\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n","  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n","Collecting timm==0.4.12\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 16.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (1.10.0+cu111)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (4.62.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.19.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (1.15.0)\n","Building wheels for collected packages: segmentation-models-pytorch, efficientnet-pytorch, pretrainedmodels\n","  Building wheel for segmentation-models-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segmentation-models-pytorch: filename=segmentation_models_pytorch-0.2.1-py3-none-any.whl size=88649 sha256=d67d97520babb7e928c4c20e68551c4a6f7d272bef3e23c31e0657d0d2888f93\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nirvcagz/wheels/fa/c5/a8/1e8af6cb04a0974db8a4a156ebd2fdd1d99ad2558d3fce49d4\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=560b4d3d0ac864c218d0e09b9c38e8f9a6d359d6d944689032a8c27bcbf3732b\n","  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=0e391dae7c59cd33fe5bb38c2db9c0af65672b4ec9badcaa36abbef92ae86e90\n","  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n","Successfully built segmentation-models-pytorch efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.1 timm-0.4.12\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2u8gGCK2uFJ6","executionInfo":{"status":"ok","timestamp":1638099207063,"user_tz":-540,"elapsed":3547,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"7df6c550-7e83-4a0f-81b0-9a51c8ca23ad"},"source":["pip install pydicom"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydicom\n","  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.2.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irDRTGHxuFM4","executionInfo":{"status":"ok","timestamp":1638099210203,"user_tz":-540,"elapsed":3150,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"53be0f35-0018-4502-a561-15004e645316"},"source":["pip install monai"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting monai\n","  Downloading monai-0.8.0-202111251823-py3-none-any.whl (709 kB)\n","\u001b[K     |████████████████████████████████| 709 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from monai) (1.10.0+cu111)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from monai) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->monai) (3.10.0.2)\n","Installing collected packages: monai\n","Successfully installed monai-0.8.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":845},"id":"cD28EWOu4ptv","executionInfo":{"status":"ok","timestamp":1638099223166,"user_tz":-540,"elapsed":12970,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"6f6f70a6-2406-4380-cca4-f981cf909931"},"source":["!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/albu/albumentations\n","  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-vqclz05m\n","  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-vqclz05m\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (1.4.1)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (0.18.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (3.13)\n","Collecting qudida>=0.0.4\n","  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.1.0) (4.1.2.30)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.1.0) (3.10.0.2)\n","Collecting opencv-python-headless>=4.0.1\n","  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n","\u001b[K     |████████████████████████████████| 47.6 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.1.0) (1.0.1)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (2.4.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (1.2.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (2021.11.2)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (7.1.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.1.0) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.1.0) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.1.0) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.1.0) (3.0.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.1.0) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (3.0.0)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-1.1.0-py3-none-any.whl size=103681 sha256=44e9a9222450ccc3b402a9f6de60d205391a15a04297706212059904abbecbd6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qvc9nr9j/wheels/63/11/1a/c77caf3ae9b9b6d57b3ee5e6a41a50f3bc12c66a70f6b90bf0\n","Successfully built albumentations\n","Installing collected packages: opencv-python-headless, qudida, albumentations\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.4.60 qudida-0.0.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Dissd-Pm4RQg"},"source":["import logging\n","import os\n","import sys\n","import tempfile\n","from glob import glob\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import ndimage\n","\n","from tqdm import tqdm\n","from pathlib import Path\n","import time\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import segmentation_models_pytorch as smp\n","import pydicom\n","import random\n","\n","import monai\n","from monai.optimizers import LearningRateFinder\n","from monai.inferers import SimpleInferer\n","from monai.metrics import DiceMetric\n","import monai.transforms as mtf\n","from monai.networks import one_hot\n","from monai.data import decollate_batch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24dW903YuFRc"},"source":["arch = \"resnet34\" # arch : \"resnet34\", \"eff-b0\", \"eff-b5\"\n","random_windowing = True # random windowing : True - random, False - simple windowing(wl : 40, ww : 400)\n","pre_valid, fine_valid = range(81,101), range(81,101)\n","wl, ww = 112,384\n","batch_size = 24\n","num_workers = 6\n","num_epochs = 10\n","# lr = 0.004"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8y08BJ-wBbG"},"source":["root_dir = \"/content/drive/MyDrive/21_2_Image_process_project/21_2_image_process_png_new\"\n","pth_dir = \"/content/drive/MyDrive/21_2_Image_process_project//pth\"\n","submission_name = \"submission8.csv\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycGHkIF5wBdS"},"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    random.seed(seed_value) \n","    if use_cuda:\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value) # gpu vars\\n\n","        torch.backends.cudnn.deterministic = True  #needed\\n\n","        torch.backends.cudnn.benchmark = False\n","        \n","seed = 42\n","random_seed(seed,True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_S2vkDzy4jaA"},"source":["def path_list(root_dir, mode, valid_num, positive_only = False):\n","    path_images = []\n","    path_labels = []\n","    if mode == \"train\":\n","        for patient in tqdm(sorted(os.listdir(os.path.join(root_dir, \"train/img\")))):\n","\n","            if patient.split('_')[-1] not in valid_num:\n","                for z_slice in sorted(os.listdir(os.path.join(root_dir, \"train/img\", patient))):\n","                    if z_slice.split('.')[-1] == \"png\":\n","                        name = z_slice.split('.')[0]\n","                        path_image = os.path.join(root_dir, \"train/img\", patient, f\"{name}.png\")\n","                        path_label = os.path.join(root_dir, \"train/mask\", f\"L_{patient.split('_')[-1]}\", f\"{name}.png\")\n","                        if positive_only:\n","                            temp_label = cv2.imread(path_label)\n","                            if np.all(temp_label == 0):\n","                                continue\n","                            else:\n","                                path_images.append(path_image)\n","                                path_labels.append(path_label)\n","                        else:\n","                            path_images.append(path_image)\n","                            path_labels.append(path_label)\n","                            \n","                \n","    else:\n","        for patient in tqdm(sorted(os.listdir(os.path.join(root_dir, \"valid/img\")))):\n","            if patient.split('_')[-1] in valid_num:\n","                for z_slice in sorted(os.listdir(os.path.join(root_dir, \"valid/img\", patient))):\n","                    if z_slice.split('.')[-1] == \"png\":\n","                        name = z_slice.split('.')[0]\n","                        path_image = os.path.join(root_dir, \"valid/img\", patient, f\"{name}.png\")\n","                        path_label = os.path.join(root_dir, \"valid/mask\", f\"L_{patient.split('_')[-1]}\", f\"{name}.png\")\n","                        if positive_only:\n","                            temp_label = cv2.imread(path_label)\n","                            if np.all(temp_label == 0):\n","                                continue\n","                            else:\n","                                path_images.append(path_image)\n","                                path_labels.append(path_label)\n","                        else:\n","                            path_images.append(path_image)\n","                            path_labels.append(path_label)\n","    return path_images, path_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NzvH8rH4r-A"},"source":["valid_num = []\n","for i in pre_valid:\n","    num = format(i, '02')\n","    valid_num.append(num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-ug5XNt4wLQ","executionInfo":{"status":"ok","timestamp":1638099254716,"user_tz":-540,"elapsed":26128,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"1735d62f-0782-4ab5-8f3d-0515cb42bec6"},"source":["train_images, train_labels = path_list(root_dir, \"train\", valid_num, False)\n","valid_images, valid_labels = path_list(root_dir, \"valid\", valid_num, False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:17<00:00,  4.58it/s]\n","100%|██████████| 20/20 [00:04<00:00,  4.97it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"Y2h-C65xuLNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638099254717,"user_tz":-540,"elapsed":39,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"365a9cf4-6413-4c91-d140-0451e40c2927"},"source":["print(f\"train images : {len(train_images)}, train labels : {len(train_labels)}\")\n","print(f\"valid images : {len(valid_images)}, valid labels : {len(valid_labels)}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train images : 12400, train labels : 12400\n","valid images : 3100, valid labels : 3100\n"]}]},{"cell_type":"code","metadata":{"id":"LxsXqXdTuLQi"},"source":["def strong_aug(p=0.5):\n","    return A.Compose([\n","        A.RandomRotate90(),\n","        A.Flip(),\n","        A.OneOf([\n","            A.GaussNoise(),\n","        ], p=0.2),\n","        A.OneOf([\n","            A.MotionBlur(p=0.2),\n","            A.MedianBlur(blur_limit=3, p=0.1),\n","            A.Blur(blur_limit=3, p=0.1),\n","        ], p=0.2),\n","        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n","        A.OneOf([\n","            A.OpticalDistortion(p=0.3),\n","            A.GridDistortion(p=0.1),\n","        ], p=0.2),\n","        A.OneOf([\n","            A.Sharpen(),\n","            A.RandomBrightnessContrast(),\n","            A.ElasticTransform()\n","        ], p=0.3),\n","        A.OneOf([\n","            A.Affine(scale = (1.2, 0.8)),\n","            A.Affine(translate_percent = (0.2, 0.2)),\n","            A.Affine(rotate = (-30, 30)),\n","            A.Affine(shear = (-20,20)),\n","            A.GridDistortion(),\n","            A.OpticalDistortion(),\n","        ], p = 0.8),\n","    ], p=p)\n","aug_func = strong_aug(p = 0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6axkGmegxNGM"},"source":["train_aug = A.Compose([\n","    #A.Normalize(mean = 101, std = 76.9, max_pixel_value = 1),\n","    A.Resize(256,256),\n","    #A.ToGray(),\n","    aug_func,\n","    ToTensorV2(),\n","])\n","\n","valid_aug = A.Compose([\n","    #A.Normalize(mean = 101, std = 76.9, max_pixel_value = 1),\n","   # A.ToGray(),\n","    A.Resize(256,256),\n","    ToTensorV2(),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFs2vlOs5gin"},"source":["class MyDataset_train(Dataset):\n","    global image\n","    def __init__(self, images_list, labels_list, transform = None):\n","        self.images_list = images_list\n","        self.labels_list = labels_list\n","        self.transform = transform\n","    def __getitem__(self, idx):\n","        image = cv2.imread(self.images_list[idx])[:,:,0]\n","        image = image.astype(np.float32)\n","        mask = cv2.imread(self.labels_list[idx])[:,:,0]\n","        \n","        if self.transform:\n","            augmented = self.transform(image = image, mask = mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","            #print(image.shape)\n","            mask = mask[np.newaxis,:,:]\n","        return image, mask\n","    def __len__(self):\n","        return len(self.images_list)\n","\n","class MyDataset_valid(Dataset):\n","    global image\n","    def __init__(self, images_list, labels_list, transform = None):\n","        self.images_list = images_list\n","        self.labels_list = labels_list\n","        self.transform = transform\n","    def __getitem__(self, idx):\n","        image = cv2.imread(self.images_list[idx])[:,:,0]\n","        image = image.astype(np.float32)\n","        mask = cv2.imread(self.labels_list[idx])[:,:,0]\n","        \n","        if self.transform:\n","            augmented = self.transform(image = image, mask = mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","            mask = mask[np.newaxis,:,:]\n","        return image, mask\n","    def __len__(self):\n","        return len(self.images_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_rEZ1ik5i_K"},"source":["trainset = MyDataset_train(train_images, train_labels, transform = train_aug)\n","validset = MyDataset_valid(valid_images, valid_labels, transform = valid_aug)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKsm63nRxNM7","executionInfo":{"status":"ok","timestamp":1638099384869,"user_tz":-540,"elapsed":5,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"055b02dd-cbc9-4e10-a9f5-9083c04323bd"},"source":["train_loader = DataLoader(trainset, batch_size=batch_size, shuffle = True, num_workers = num_workers)\n","valid_loader = DataLoader(validset, batch_size=batch_size, shuffle = False, num_workers = num_workers)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"PTBJUT9a5mRF"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuiYPKMbxNPi"},"source":["if arch == \"resnet34\":\n","    model = smp.Unet(encoder_name = \"resnet34\", encoder_weights = \"imagenet\", in_channels = 1, classes = 2)\n","elif arch == \"resnet50\":\n","    model = smp.Unet(encoder_name = \"resnet50\", encoder_weights = \"imagenet\", in_channels = 1, classes = 2)\n","elif arch == \"resnet101\":\n","    model = smp.Unet(encoder_name = \"resnet101\", encoder_weights = \"imagenet\", in_channels = 1, classes = 2)\n","elif arch == \"eff-b5\":\n","    model = smp.Unet(encoder_name = \"timm-efficientnet-b5\", encoder_weights = \"noisy-student\",in_channels = 1, classes = 2)\n","elif arch == \"eff-b0\":\n","    model = smp.Unet(encoder_name = \"timm-efficientnet-b0\", encoder_weights = \"noisy-student\",in_channels = 1, classes = 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujOZBWdo53kK","executionInfo":{"status":"ok","timestamp":1638099390133,"user_tz":-540,"elapsed":237,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"d1973a24-e09f-4c8f-ca9d-80ed98b59439"},"source":["net = model.to(device)\n","print(type(net))\n","net"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'segmentation_models_pytorch.unet.model.Unet'>\n"]},{"output_type":"execute_result","data":{"text/plain":["Unet(\n","  (encoder): ResNetEncoder(\n","    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (decoder): UnetDecoder(\n","    (center): Identity()\n","    (blocks): ModuleList(\n","      (0): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (1): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (4): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","    )\n","  )\n","  (segmentation_head): SegmentationHead(\n","    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): Identity()\n","    (2): Activation(\n","      (activation): Identity()\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"X4RIKL4v55eJ"},"source":["import torch\n","from torch import nn\n","from torchsummary import summary as summary_\n","from torch.nn import functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsqBFXP8571_","executionInfo":{"status":"ok","timestamp":1638099400089,"user_tz":-540,"elapsed":244,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"69b58b45-c894-4679-9718-bd751dadca5d"},"source":["summary_(model,(1,256,256),batch_size=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [1, 64, 128, 128]           3,136\n","       BatchNorm2d-2          [1, 64, 128, 128]             128\n","              ReLU-3          [1, 64, 128, 128]               0\n","         MaxPool2d-4            [1, 64, 64, 64]               0\n","            Conv2d-5            [1, 64, 64, 64]          36,864\n","       BatchNorm2d-6            [1, 64, 64, 64]             128\n","              ReLU-7            [1, 64, 64, 64]               0\n","            Conv2d-8            [1, 64, 64, 64]          36,864\n","       BatchNorm2d-9            [1, 64, 64, 64]             128\n","             ReLU-10            [1, 64, 64, 64]               0\n","       BasicBlock-11            [1, 64, 64, 64]               0\n","           Conv2d-12            [1, 64, 64, 64]          36,864\n","      BatchNorm2d-13            [1, 64, 64, 64]             128\n","             ReLU-14            [1, 64, 64, 64]               0\n","           Conv2d-15            [1, 64, 64, 64]          36,864\n","      BatchNorm2d-16            [1, 64, 64, 64]             128\n","             ReLU-17            [1, 64, 64, 64]               0\n","       BasicBlock-18            [1, 64, 64, 64]               0\n","           Conv2d-19            [1, 64, 64, 64]          36,864\n","      BatchNorm2d-20            [1, 64, 64, 64]             128\n","             ReLU-21            [1, 64, 64, 64]               0\n","           Conv2d-22            [1, 64, 64, 64]          36,864\n","      BatchNorm2d-23            [1, 64, 64, 64]             128\n","             ReLU-24            [1, 64, 64, 64]               0\n","       BasicBlock-25            [1, 64, 64, 64]               0\n","           Conv2d-26           [1, 128, 32, 32]          73,728\n","      BatchNorm2d-27           [1, 128, 32, 32]             256\n","             ReLU-28           [1, 128, 32, 32]               0\n","           Conv2d-29           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-30           [1, 128, 32, 32]             256\n","           Conv2d-31           [1, 128, 32, 32]           8,192\n","      BatchNorm2d-32           [1, 128, 32, 32]             256\n","             ReLU-33           [1, 128, 32, 32]               0\n","       BasicBlock-34           [1, 128, 32, 32]               0\n","           Conv2d-35           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-36           [1, 128, 32, 32]             256\n","             ReLU-37           [1, 128, 32, 32]               0\n","           Conv2d-38           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-39           [1, 128, 32, 32]             256\n","             ReLU-40           [1, 128, 32, 32]               0\n","       BasicBlock-41           [1, 128, 32, 32]               0\n","           Conv2d-42           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-43           [1, 128, 32, 32]             256\n","             ReLU-44           [1, 128, 32, 32]               0\n","           Conv2d-45           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-46           [1, 128, 32, 32]             256\n","             ReLU-47           [1, 128, 32, 32]               0\n","       BasicBlock-48           [1, 128, 32, 32]               0\n","           Conv2d-49           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-50           [1, 128, 32, 32]             256\n","             ReLU-51           [1, 128, 32, 32]               0\n","           Conv2d-52           [1, 128, 32, 32]         147,456\n","      BatchNorm2d-53           [1, 128, 32, 32]             256\n","             ReLU-54           [1, 128, 32, 32]               0\n","       BasicBlock-55           [1, 128, 32, 32]               0\n","           Conv2d-56           [1, 256, 16, 16]         294,912\n","      BatchNorm2d-57           [1, 256, 16, 16]             512\n","             ReLU-58           [1, 256, 16, 16]               0\n","           Conv2d-59           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-60           [1, 256, 16, 16]             512\n","           Conv2d-61           [1, 256, 16, 16]          32,768\n","      BatchNorm2d-62           [1, 256, 16, 16]             512\n","             ReLU-63           [1, 256, 16, 16]               0\n","       BasicBlock-64           [1, 256, 16, 16]               0\n","           Conv2d-65           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-66           [1, 256, 16, 16]             512\n","             ReLU-67           [1, 256, 16, 16]               0\n","           Conv2d-68           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-69           [1, 256, 16, 16]             512\n","             ReLU-70           [1, 256, 16, 16]               0\n","       BasicBlock-71           [1, 256, 16, 16]               0\n","           Conv2d-72           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-73           [1, 256, 16, 16]             512\n","             ReLU-74           [1, 256, 16, 16]               0\n","           Conv2d-75           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-76           [1, 256, 16, 16]             512\n","             ReLU-77           [1, 256, 16, 16]               0\n","       BasicBlock-78           [1, 256, 16, 16]               0\n","           Conv2d-79           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-80           [1, 256, 16, 16]             512\n","             ReLU-81           [1, 256, 16, 16]               0\n","           Conv2d-82           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-83           [1, 256, 16, 16]             512\n","             ReLU-84           [1, 256, 16, 16]               0\n","       BasicBlock-85           [1, 256, 16, 16]               0\n","           Conv2d-86           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-87           [1, 256, 16, 16]             512\n","             ReLU-88           [1, 256, 16, 16]               0\n","           Conv2d-89           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-90           [1, 256, 16, 16]             512\n","             ReLU-91           [1, 256, 16, 16]               0\n","       BasicBlock-92           [1, 256, 16, 16]               0\n","           Conv2d-93           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-94           [1, 256, 16, 16]             512\n","             ReLU-95           [1, 256, 16, 16]               0\n","           Conv2d-96           [1, 256, 16, 16]         589,824\n","      BatchNorm2d-97           [1, 256, 16, 16]             512\n","             ReLU-98           [1, 256, 16, 16]               0\n","       BasicBlock-99           [1, 256, 16, 16]               0\n","          Conv2d-100             [1, 512, 8, 8]       1,179,648\n","     BatchNorm2d-101             [1, 512, 8, 8]           1,024\n","            ReLU-102             [1, 512, 8, 8]               0\n","          Conv2d-103             [1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-104             [1, 512, 8, 8]           1,024\n","          Conv2d-105             [1, 512, 8, 8]         131,072\n","     BatchNorm2d-106             [1, 512, 8, 8]           1,024\n","            ReLU-107             [1, 512, 8, 8]               0\n","      BasicBlock-108             [1, 512, 8, 8]               0\n","          Conv2d-109             [1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-110             [1, 512, 8, 8]           1,024\n","            ReLU-111             [1, 512, 8, 8]               0\n","          Conv2d-112             [1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-113             [1, 512, 8, 8]           1,024\n","            ReLU-114             [1, 512, 8, 8]               0\n","      BasicBlock-115             [1, 512, 8, 8]               0\n","          Conv2d-116             [1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-117             [1, 512, 8, 8]           1,024\n","            ReLU-118             [1, 512, 8, 8]               0\n","          Conv2d-119             [1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-120             [1, 512, 8, 8]           1,024\n","            ReLU-121             [1, 512, 8, 8]               0\n","      BasicBlock-122             [1, 512, 8, 8]               0\n","   ResNetEncoder-123  [[-1, 1, 256, 256], [-1, 64, 128, 128], [-1, 64, 64, 64], [-1, 128, 32, 32], [-1, 256, 16, 16], [-1, 512, 8, 8]]               0\n","        Identity-124             [1, 512, 8, 8]               0\n","        Identity-125           [1, 768, 16, 16]               0\n","       Attention-126           [1, 768, 16, 16]               0\n","          Conv2d-127           [1, 256, 16, 16]       1,769,472\n","     BatchNorm2d-128           [1, 256, 16, 16]             512\n","            ReLU-129           [1, 256, 16, 16]               0\n","          Conv2d-130           [1, 256, 16, 16]         589,824\n","     BatchNorm2d-131           [1, 256, 16, 16]             512\n","            ReLU-132           [1, 256, 16, 16]               0\n","        Identity-133           [1, 256, 16, 16]               0\n","       Attention-134           [1, 256, 16, 16]               0\n","    DecoderBlock-135           [1, 256, 16, 16]               0\n","        Identity-136           [1, 384, 32, 32]               0\n","       Attention-137           [1, 384, 32, 32]               0\n","          Conv2d-138           [1, 128, 32, 32]         442,368\n","     BatchNorm2d-139           [1, 128, 32, 32]             256\n","            ReLU-140           [1, 128, 32, 32]               0\n","          Conv2d-141           [1, 128, 32, 32]         147,456\n","     BatchNorm2d-142           [1, 128, 32, 32]             256\n","            ReLU-143           [1, 128, 32, 32]               0\n","        Identity-144           [1, 128, 32, 32]               0\n","       Attention-145           [1, 128, 32, 32]               0\n","    DecoderBlock-146           [1, 128, 32, 32]               0\n","        Identity-147           [1, 192, 64, 64]               0\n","       Attention-148           [1, 192, 64, 64]               0\n","          Conv2d-149            [1, 64, 64, 64]         110,592\n","     BatchNorm2d-150            [1, 64, 64, 64]             128\n","            ReLU-151            [1, 64, 64, 64]               0\n","          Conv2d-152            [1, 64, 64, 64]          36,864\n","     BatchNorm2d-153            [1, 64, 64, 64]             128\n","            ReLU-154            [1, 64, 64, 64]               0\n","        Identity-155            [1, 64, 64, 64]               0\n","       Attention-156            [1, 64, 64, 64]               0\n","    DecoderBlock-157            [1, 64, 64, 64]               0\n","        Identity-158         [1, 128, 128, 128]               0\n","       Attention-159         [1, 128, 128, 128]               0\n","          Conv2d-160          [1, 32, 128, 128]          36,864\n","     BatchNorm2d-161          [1, 32, 128, 128]              64\n","            ReLU-162          [1, 32, 128, 128]               0\n","          Conv2d-163          [1, 32, 128, 128]           9,216\n","     BatchNorm2d-164          [1, 32, 128, 128]              64\n","            ReLU-165          [1, 32, 128, 128]               0\n","        Identity-166          [1, 32, 128, 128]               0\n","       Attention-167          [1, 32, 128, 128]               0\n","    DecoderBlock-168          [1, 32, 128, 128]               0\n","          Conv2d-169          [1, 16, 256, 256]           4,608\n","     BatchNorm2d-170          [1, 16, 256, 256]              32\n","            ReLU-171          [1, 16, 256, 256]               0\n","          Conv2d-172          [1, 16, 256, 256]           2,304\n","     BatchNorm2d-173          [1, 16, 256, 256]              32\n","            ReLU-174          [1, 16, 256, 256]               0\n","        Identity-175          [1, 16, 256, 256]               0\n","       Attention-176          [1, 16, 256, 256]               0\n","    DecoderBlock-177          [1, 16, 256, 256]               0\n","     UnetDecoder-178          [1, 16, 256, 256]               0\n","          Conv2d-179           [1, 2, 256, 256]             290\n","        Identity-180           [1, 2, 256, 256]               0\n","        Identity-181           [1, 2, 256, 256]               0\n","      Activation-182           [1, 2, 256, 256]               0\n","================================================================\n","Total params: 24,430,242\n","Trainable params: 24,430,242\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.25\n","Forward/backward pass size (MB): 330.50\n","Params size (MB): 93.19\n","Estimated Total Size (MB): 423.94\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzYgyRhNxNR9","executionInfo":{"status":"ok","timestamp":1638099403306,"user_tz":-540,"elapsed":239,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"d15a33a0-6d26-4fff-aabb-a38cb4e13770"},"source":["model = model.to(device)\n","# loss_function = monai.losses.DiceCELoss(include_background=False, softmax = True, to_onehot_y = True, ce_weight = torch.tensor([0.3, 0.3,0.4]).cuda())\n","loss_function = monai.losses.GeneralizedDiceLoss(include_background=False, softmax = True, to_onehot_y = True)\n","post_trans = mtf.Compose(\n","    [mtf.Activations(softmax=True)]\n",")\n","post_label = mtf.AsDiscrete(to_onehot=True, n_classes=2)\n","post_pred = mtf.AsDiscrete(argmax=True, to_onehot=True, n_classes=2)\n","dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n","inferer = monai.inferers.SimpleInferer()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/monai/transforms/post/array.py:177: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.\n","  warnings.warn(\"`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPAuaAMTxUTr","executionInfo":{"status":"ok","timestamp":1638099668444,"user_tz":-540,"elapsed":261993,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"9c390aff-5819-45f0-877e-5dc72ad9077f"},"source":["lower_lr, upper_lr = 1e-5, 1e-0\n","optimizer = torch.optim.Adam(model.parameters(), lower_lr)\n","lr_finder = LearningRateFinder(model, optimizer, loss_function, device=device)\n","lr_finder.range_test(train_loader, valid_loader, end_lr=upper_lr, num_iter=5)\n","steepest_lr, _ = lr_finder.get_steepest_gradient()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Computing optimal learning rate: 100%|██████████| 5/5 [04:21<00:00, 52.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Resetting model and optimizer\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHvF4B5SxUWJ","executionInfo":{"status":"ok","timestamp":1638099668445,"user_tz":-540,"elapsed":33,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"5476a1a1-5e33-4edf-d6bb-c416616f3b1b"},"source":["print(steepest_lr)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.056234132519034905\n"]}]},{"cell_type":"code","metadata":{"id":"a7S0cg54xUY7"},"source":["optimizer = torch.optim.Adam(model.parameters(), steepest_lr)\n","\n","\n","val_interval = 1\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = list()\n","metric_values = list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wq9RMkJIxUbd","executionInfo":{"status":"ok","timestamp":1638102379141,"user_tz":-540,"elapsed":2710072,"user":{"displayName":"장현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00837874340781859302"}},"outputId":"a4cf361b-0f30-421e-86b4-f458fd1344b9"},"source":["for epoch in range(num_epochs):\n","        \n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch}/{num_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    \n","    for batch_data in tqdm(train_loader):\n","        step += 1\n","        inputs, labels = batch_data[0].to(device).float(), batch_data[1].to(device).long()\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_len = len(trainset) // train_loader.batch_size\n","        if step % 100 == 0:\n","            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\",flush = True)\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            metric_sum = 0.0\n","            metric_count = 0\n","            val_images = None\n","            val_labels = None\n","            val_outputs = None\n","            val_step = 0\n","            val_epoch_loss = 0\n","            dice_vals = list()\n","            \n","            for val_data in tqdm(valid_loader):\n","                val_step += 1\n","                val_images, val_labels = val_data[0].to(device).float(), val_data[1].to(device).long()\n","                val_outputs = model(val_images)\n","                val_labels_list = decollate_batch(val_labels)\n","                val_labels_convert = [\n","                post_label(val_label_tensor) for val_label_tensor in val_labels_list\n","                ]\n","                val_outputs_list = decollate_batch(val_outputs)\n","                val_output_convert = [\n","                    post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list\n","                ]\n","                dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n","                dice = dice_metric.aggregate().item()\n","                dice_vals.append(dice)\n","#                 val_loss = loss_function(val_outputs, val_labels)\n","#                 val_epoch_loss += loss.item()\n","#                 val_epoch_len = len(validset) // valid_loader.batch_size\n","            \n","            metric = np.mean(dice_vals)\n","#             val_epoch_loss /= val_step\n","#             metric = val_epoch_loss\n","#             metric_values.append(metric)\n","            if metric > best_metric:\n","                best_metric = metric\n","                best_metric_epoch = epoch + 1\n","                ppath = Path(os.path.join(pth_dir, f\"{submission_name.split('.')[0]}/pre-best_model.pth\"))\n","                ppath.parent.mkdir(parents = True, exist_ok = True)\n","                torch.save(model.state_dict(), str(ppath))\n","                print(\"saved new best metric model\")\n","            print(\n","                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n","                    epoch + 1, metric, best_metric, best_metric_epoch\n","                )\n","            )\n","    if epoch > 7:\n","        ppath = Path(os.path.join(pth_dir, f\"{submission_name.split('.')[0]}/best_model_e{epoch}.pth\"))\n","        ppath.parent.mkdir(parents = True, exist_ok = True)\n","        torch.save(model.state_dict(), str(ppath))\n","print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","epoch 0/10\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"," 19%|█▉        | 99/517 [02:21<07:55,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.1554\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [04:43<08:52,  1.68s/it]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.2191\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [07:02<05:01,  1.38s/it]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1361\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [09:26<02:45,  1.41s/it]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1511\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [11:48<00:44,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.3095\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [12:09<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1 average loss: 0.2013\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:16<00:00,  7.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 1 current mean dice: 0.4464 best mean dice: 0.4464 at epoch 1\n","----------\n","epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:43<02:50,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.2772\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:22<01:55,  2.74it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.2312\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:59<01:17,  2.81it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1162\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:38<00:44,  2.64it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1892\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:15<00:06,  2.67it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1650\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:21<00:00,  2.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 2 average loss: 0.1877\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:16<00:00,  7.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 2 current mean dice: 0.4134 best mean dice: 0.4464 at epoch 1\n","----------\n","epoch 2/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:39<02:38,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.1188\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:17<01:59,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.1171\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:55<01:23,  2.60it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1969\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:32<00:44,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1040\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:11<00:06,  2.71it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1950\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:17<00:00,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 3 average loss: 0.1807\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:16<00:00,  7.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 3 current mean dice: 0.4289 best mean dice: 0.4464 at epoch 1\n","----------\n","epoch 3/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:39<02:41,  2.60it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.1288\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:17<01:57,  2.72it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.1689\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:55<01:15,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1721\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:35<00:42,  2.78it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.2518\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:11<00:06,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1200\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:17<00:00,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 4 average loss: 0.1793\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:17<00:00,  7.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 4 current mean dice: 0.4397 best mean dice: 0.4464 at epoch 1\n","----------\n","epoch 4/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:40<02:41,  2.59it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.1557\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:20<02:02,  2.60it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.2158\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:58<01:23,  2.60it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.2227\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:35<00:45,  2.60it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1531\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:13<00:06,  2.72it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.2057\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:20<00:00,  2.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 5 average loss: 0.1713\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:17<00:00,  7.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 5 current mean dice: 0.4564 best mean dice: 0.4564 at epoch 5\n","----------\n","epoch 5/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:41<02:31,  2.76it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.1521\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:20<03:08,  1.69it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.2265\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:58<01:23,  2.61it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1803\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:37<00:41,  2.82it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1589\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:15<00:06,  2.81it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.0457\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:22<00:00,  2.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 6 average loss: 0.1709\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:17<00:00,  7.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 6 current mean dice: 0.4741 best mean dice: 0.4741 at epoch 6\n","----------\n","epoch 6/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:40<02:24,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.2057\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:18<01:56,  2.72it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.1129\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:55<01:20,  2.71it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1331\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:33<00:44,  2.67it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1296\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:11<00:06,  2.69it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1426\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:18<00:00,  2.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 7 average loss: 0.1654\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:18<00:00,  6.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 7 current mean dice: 0.4840 best mean dice: 0.4840 at epoch 7\n","----------\n","epoch 7/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:40<02:42,  2.57it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.2043\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:21<01:56,  2.73it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.2600\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:59<01:19,  2.75it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1132\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:36<00:46,  2.55it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1371\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:15<00:07,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1619\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:21<00:00,  2.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 8 average loss: 0.1633\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:18<00:00,  7.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 8 current mean dice: 0.4901 best mean dice: 0.4901 at epoch 8\n","----------\n","epoch 8/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:41<02:43,  2.56it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.2235\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:21<02:06,  2.51it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.1521\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:59<01:22,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.1265\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:37<00:47,  2.47it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.1241\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:14<00:06,  2.72it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1158\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:20<00:00,  2.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 9 average loss: 0.1597\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:20<00:00,  6.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 9 current mean dice: 0.4969 best mean dice: 0.4969 at epoch 9\n","----------\n","epoch 9/10\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 99/517 [00:40<02:31,  2.77it/s]"]},{"output_type":"stream","name":"stdout","text":["100/516, train_loss: 0.0700\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 199/517 [01:20<01:52,  2.82it/s]"]},{"output_type":"stream","name":"stdout","text":["200/516, train_loss: 0.1216\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 299/517 [01:57<01:14,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["300/516, train_loss: 0.0141\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 399/517 [02:34<00:40,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["400/516, train_loss: 0.0281\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 499/517 [03:11<00:06,  2.70it/s]"]},{"output_type":"stream","name":"stdout","text":["500/516, train_loss: 0.1874\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 517/517 [03:17<00:00,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 10 average loss: 0.1592\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 130/130 [00:19<00:00,  6.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 10 current mean dice: 0.5049 best mean dice: 0.5049 at epoch 10\n","train completed, best_metric: 0.5049 at epoch: 10\n"]}]},{"cell_type":"code","metadata":{"id":"mGOgKlJXxUeI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ovIM200xUgi"},"source":[""],"execution_count":null,"outputs":[]}]}